# Fast Training Configuration (for debugging)

# Optimization
learning_rate: 5e-5
weight_decay: 0.01
warmup_ratio: 0.1
max_grad_norm: 1.0

# Training schedule
num_epochs: 2
batch_size: 8
eval_batch_size: 16
gradient_accumulation_steps: 1

# Evaluation
eval_every_n_epochs: 1
save_every_n_epochs: 1
early_stopping_patience: 2

# Device
device: "auto"
mixed_precision: true
